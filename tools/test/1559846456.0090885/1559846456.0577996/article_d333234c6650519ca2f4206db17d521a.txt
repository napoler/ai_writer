Church、浣军、熊辉加盟百度研究院，同时百度研究院“扩军”：在三大实验室的基础上增加商业智能实验室和机器人与自动驾驶实验室。
至此，百度研究院全新升级，建立起包括七位世界级科学家、五大实验室的“全明星”阵容。
另外，在近期百度语音技术也迎来了半年内的重大突破。 
Church、浣军、熊辉加盟百度研究院。
至此，百度研究院全新升级，建立起包括七位世界级科学家、五大实验室的“全明星”阵容。 
会上，百度副总裁、AI技术平台体系（AIG）总负责人、百度研究院院长王海峰表示，这是百度研究院新征程的开始。
百度研究院将聚焦前瞻基础研究，布局百度人工智能未来发展方向，服务百度作为人工智能公司的长期发展战略。 
百度研究院的科学家团队再度壮大，堪称百度研究院史上最强阵容。 
Ward Church、浣军、熊辉均是AI领域的世界级学者。 
是自然语言处理领域的大师级人物，是经验主义方法的奠基人之一。 
Watson Research Center工作。 
Computational Linguistics）主席，现为ACL Fellow。 
**浣军** 为美国堪萨斯大学电子工程和计算机系正教授、博士生导师。
曾任美国国家基金委项目主任，主管大数据， 此前任堪萨斯大学终身教授。 
浣军教授长期从事数据挖掘和机器学习的理论、算法和应用的研究，研究领域涉及大数据，生物信息学、药物基因组学等。 
生物信息学和计算生命科学实验室主任， 国家分子探针研究中心化学信息学部主任等职。 
新泽西州立大学终身正教授。 
(终身教授)、RBS院长讲席教授，并担任中国科学技术大学大师讲席教授。 
熊辉教授主要研究领域涵盖数据挖掘、大数据、人工智能；获得的部分荣誉包括ACM杰出科学家，长江讲座教授，海外杰青B类（海外及港澳学者合作研究基金）。 
Church表示，“人工智能的价值有目共睹。
百度不仅致力于基础研究，还创造性地将实验室技术转化为真实的应用，让我们的世界变得更加美好。
我很高兴能够加入这个团队，与才华横溢的研究者和工程师们一起探索人工智能的前沿技术。 
升级后，百度研究院由原来的三个实验室增加为五个实验室，分别是深度学习实验室（IDL）、大数据实验室（BDL）、硅谷人工智能实验室（SVAIL）、商业智能实验室（BIL）、机器人与自动驾驶实验室（RAL）。 
**重点关注机器人技术，尤其是在自动驾驶领域夯实百度无人驾驶基础技术。 
百度研究院将以人工智能技术的前瞻性和基础性研究为核心，以其长期创新突破为目标，并与百度其它技术部门互补协同，共同推动百度AI的跨越式发展及商业化落地。 
百度于2013年成立深度学习研究院，主要研究机器学习和通用人工智能技术。 
大数据实验室重点研究基于大数据的基础算法和机器学习、数据挖掘、知识发现等技术。 
硅谷人工智能实验室重点研究深度学习、语音技术、自然语言处理和高性能计算。 
商业智能实验室主要研究用于新兴数据密集型应用的高效数据分析技术。 
机器人与自动驾驶实验室开展包括计算机视觉、机器学习等在内的跨学科研究，并在实现在机器人，特别是自动驾驶上的应用。 
回望百度AI的发展历程，百度引领人工智能时代的决心清晰可见。 
早在2013年初，百度就组建了深度学习研究院，即百度研究院的前身。
百度以搜索立身，自创立之初就与自然语言处理等人工智能技术息息相关。
2014年，百度研究院正式成立，包括IDL、BDL和SVAIL。
2017年3月，百度明确把人工智能作为公司发展战略，整合AI核心技术，成立AI技术平台体系（AIG），任命副总裁王海峰为总负责人，推动研发领先的AI核心技术，对内赋能重要业务，对外繁荣技术生态，加速AI商业化落地。 
开放平台对外开放包含语音、图像、视频、增强现实、自然语音处理等在内的90多项AI核心能力，同时积极与行业合作伙伴和广大开发者一起共建AI技术生态。 
“人工智能是第四次工业革命的核心驱动力，不仅促进了各行各业的变革，也在催生新的行业；同时，人工智能系统也在与用户、需求场景的互动中持续进化，”王海峰认为，百度已经是一家AI公司，是人工智能技术研究和创新的理想之地。 
前不久，百度输入法v8.0版本正式上线，百度将语音技术Deep Peak2模型公诸于众。 
的上下文无关音素组合建模”，这是百度近半年内语音技术领域的重大突破。 
在传统的语音技术中，“上下文相关建模”是已经应用了十几年的成熟技术，指同一个音素，由于其左边或者右边相连的音素不同，则被定义成不同的模单元。
百度此次推出的“上下文无关建模”是指一个音素，无论左右相连的音素是什么，都被定义成唯一的一个单元，这相比十几年来语音上使用的三音素上下文相关的建模，是一个很大的突破。 
**其中，最大的特点是建模单元大幅减少。 
以前三音素的建模单元基本上有一万个音素组合，但是在上下文无关的建模上，组合被缩小到1000个。
这样带来的好处是，减少决策树聚类等技术环节，提升语音性能。 
因为建模单元少了，因此解码空间变得非常简单，解码的速度比以前提升10倍。 
2实际上是把声学和语言文本分开训练的模型，既适合深度神经网络端到端的特点，不用考虑输入输出的问题，还考虑到音素之间的组合，是在传统语音技术上的提升。 
2模型的这些优势，能够把口语和朗读语言组合在一起进行训练，也能把中文和英文混合在一起建模，大幅提升中英文、多种口音、多种风格（如朗读、聊天、轻声）混合输入的识别准确率，聊天场景下的相对正确率较行业领先水平提升20%，让机器更轻松适应用户的自然对话。 
Models（“使用序列到序列模型的语音识别模型”）论文，描述了一个新的端到端模型，它的性能优于目前已商用的传统方法，新的的端到端系统的词错率（WER）降到5.6％。
不过，这些模型不能实时处理语音。 
百度是国最早将深度学习应用到语音识别上的公司，高亮在发布会上介绍，百度从2012年开始，每年都会上一个新的模型，每一个模型都会形成技术突破，每个技术突破都会带来准确率的提升。 
高亮说，Deep Peak 2是在Deep Speech的基础上升级的建模方式，前者比后者更加灵活，灵活性主要体现在生僻字和中英文识别上。 
不过，两代Deep Speech均属于论文层面，涉及工程层面的应用较少，现在，百度语音迎来了“王海峰时代”，并加速进行商业化落地。 
**“百度输入法是百度AI技术应用的一个桥头堡。
”** 王海峰说，百度很多技术首先会在像输入法这样的产品中去应用。



